{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b63a336",
   "metadata": {},
   "source": [
    "# Diffusion model training"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### This notebook aims to launch the training of the main diffusion model. It does not train the classifier and regressor that are used to perform *classifier* and *regressor guidance*. The trainings of the three models (diffusion model, regressor and classifier) are independant."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62e82787",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T21:55:32.967357Z",
     "end_time": "2023-11-27T21:55:32.995200Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76386936",
   "metadata": {},
   "source": [
    "The environment variable 'TOPODIFF_LOGDIR' defines the directory where the logs and model checkpoints will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7dd10fb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T21:55:32.986095Z",
     "end_time": "2023-11-27T21:55:33.026066Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ['TOPODIFF_LOGDIR'] = './checkpoints/diff_logdir'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dee131",
   "metadata": {},
   "source": [
    "The 'TRAIN FLAGS', 'MODEL_FLAGS', 'DIFFUSION_FLAGS' and 'DATA_FLAGS' respectively set the training parameters, the model and diffusion hyperparameters and the directories where the training data are.\n",
    "\n",
    "The default values indicated below correspond to the hyperparameters indicated in the Appendix to the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114c87e5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T21:55:32.999286Z",
     "end_time": "2023-11-27T21:55:33.026066Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_FLAGS=\"--batch_size 32 --save_interval 20000 --use_fp16 True\"\n",
    "MODEL_FLAGS=\"--image_size 64 --num_channels 128 --num_res_blocks 3 --learn_sigma True --dropout 0.3\"\n",
    "DIFFUSION_FLAGS=\"--diffusion_steps 1000 --noise_schedule cosine\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d80c5",
   "metadata": {},
   "source": [
    "In order to run the training, make sure you have placed the data folder at the root of this directory.\n",
    "\n",
    "All the images, physical fields, and load arrays must be altogether in the same folder (done by default in the data directory that we provide you with)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7db9347f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-11-27T21:55:33.016441Z",
     "end_time": "2023-11-27T21:55:33.041474Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FLAGS=\"--data_dir ./data/dataset_1_diff/training_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc9ea4ea",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "start_time": "2023-11-27T21:55:33.030110Z",
     "end_time": "2023-11-27T21:55:36.498889Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./checkpoints/diff_logdir\n",
      "creating model and diffusion...\n",
      "creating data loader...\n",
      "training...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module '__main__' has no attribute '__spec__'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32mD:\\CodeSave\\GitCode\\topodiff\\scripts\\image_train.py:82\u001B[0m\n\u001B[0;32m     78\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m---> 82\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\CodeSave\\GitCode\\topodiff\\scripts\\image_train.py:40\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m     33\u001B[0m data \u001B[38;5;241m=\u001B[39m load_data(\n\u001B[0;32m     34\u001B[0m     data_dir\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mdata_dir,\n\u001B[0;32m     35\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mbatch_size,\n\u001B[0;32m     36\u001B[0m     image_size\u001B[38;5;241m=\u001B[39margs\u001B[38;5;241m.\u001B[39mimage_size,\n\u001B[0;32m     37\u001B[0m )\n\u001B[0;32m     39\u001B[0m logger\u001B[38;5;241m.\u001B[39mlog(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 40\u001B[0m \u001B[43mTrainLoop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdiffusion\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiffusion\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     43\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     44\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     45\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmicrobatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmicrobatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     46\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mema_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mema_rate\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlog_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     49\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresume_checkpoint\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresume_checkpoint\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     51\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_fp16\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43muse_fp16\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     52\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfp16_scale_growth\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp16_scale_growth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     53\u001B[0m \u001B[43m    \u001B[49m\u001B[43mschedule_sampler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mschedule_sampler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweight_decay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight_decay\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[43m    \u001B[49m\u001B[43mlr_anneal_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlr_anneal_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     56\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\CodeSave\\GitCode\\topodiff\\topodiff\\train_util.py:155\u001B[0m, in \u001B[0;36mTrainLoop.run_loop\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrun_loop\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m (\n\u001B[0;32m    152\u001B[0m         \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_anneal_steps\n\u001B[0;32m    153\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresume_step \u001B[38;5;241m<\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_anneal_steps\n\u001B[0;32m    154\u001B[0m     ):\n\u001B[1;32m--> 155\u001B[0m         batch, batch_cons, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mnext\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    156\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrun_step(batch, batch_cons)\n\u001B[0;32m    157\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstep \u001B[38;5;241m%\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlog_interval \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mD:\\CodeSave\\GitCode\\topodiff\\topodiff\\image_datasets_diffusion_model.py:52\u001B[0m, in \u001B[0;36mload_data\u001B[1;34m(data_dir, batch_size, image_size, deterministic)\u001B[0m\n\u001B[0;32m     48\u001B[0m     loader \u001B[38;5;241m=\u001B[39m DataLoader(\n\u001B[0;32m     49\u001B[0m         dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, num_workers\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, drop_last\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m     50\u001B[0m     )\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 52\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m loader\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:438\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    436\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[0;32m    437\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 438\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:386\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    384\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[1;32m--> 386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1039\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[1;34m(self, loader)\u001B[0m\n\u001B[0;32m   1032\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1033\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[0;32m   1034\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[0;32m   1035\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[0;32m   1036\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[0;32m   1037\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[0;32m   1038\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[1;32m-> 1039\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1040\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[0;32m   1041\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\multiprocessing\\process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[0;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    120\u001B[0m _cleanup()\n\u001B[1;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[0;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[0;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\multiprocessing\\context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\multiprocessing\\context.py:327\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[1;34m(process_obj)\u001B[0m\n\u001B[0;32m    324\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m    325\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m    326\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_win32\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[1;32m--> 327\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\multiprocessing\\popen_spawn_win32.py:45\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[1;34m(self, process_obj)\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m---> 45\u001B[0m     prep_data \u001B[38;5;241m=\u001B[39m \u001B[43mspawn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_preparation_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     47\u001B[0m     \u001B[38;5;66;03m# read end of pipe will be duplicated by the child process\u001B[39;00m\n\u001B[0;32m     48\u001B[0m     \u001B[38;5;66;03m# -- see spawn_main() in spawn.py.\u001B[39;00m\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;66;03m# bpo-33929: Previously, the read end of pipe was \"stolen\" by the child\u001B[39;00m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;66;03m# process, but it leaked a handle if the child process had been\u001B[39;00m\n\u001B[0;32m     52\u001B[0m     \u001B[38;5;66;03m# terminated before it could steal the handle from the parent process.\u001B[39;00m\n\u001B[0;32m     53\u001B[0m     rhandle, whandle \u001B[38;5;241m=\u001B[39m _winapi\u001B[38;5;241m.\u001B[39mCreatePipe(\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\topodiff\\lib\\multiprocessing\\spawn.py:183\u001B[0m, in \u001B[0;36mget_preparation_data\u001B[1;34m(name)\u001B[0m\n\u001B[0;32m    180\u001B[0m \u001B[38;5;66;03m# Figure out whether to initialise main in the subprocess as a module\u001B[39;00m\n\u001B[0;32m    181\u001B[0m \u001B[38;5;66;03m# or through direct execution (or to leave it alone entirely)\u001B[39;00m\n\u001B[0;32m    182\u001B[0m main_module \u001B[38;5;241m=\u001B[39m sys\u001B[38;5;241m.\u001B[39mmodules[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m--> 183\u001B[0m main_mod_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[43mmain_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__spec__\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m    184\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m main_mod_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    185\u001B[0m     d[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minit_main_from_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m main_mod_name\n",
      "\u001B[1;31mAttributeError\u001B[0m: module '__main__' has no attribute '__spec__'"
     ]
    }
   ],
   "source": [
    "%run scripts/image_train.py $MODEL_FLAGS $DIFFUSION_FLAGS $TRAIN_FLAGS $DATA_FLAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b0f4ff",
   "metadata": {},
   "source": [
    "By the end of the training, you should get in the diff_logdir a series of checkpoints. You can then use the last checkpoint as the difusion model when sampling from TopoDiff (see the notebook **4_TopoDiff_sample**)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
